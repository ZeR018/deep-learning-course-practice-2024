# Лабораторная работа 3: Перенос знаний с использованием PyTorch

## Цели работы

Цель данной работы — изучить и реализовать метод переноса знаний (transfer learning) в глубоких нейронных сетях для решения задачи классификации отходов на основе набора данных [Garbage Classification]
(https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification). Предлагается применение метода переноса знаний к известным моделям глубокого обучения, обученных на наборе данных ImageNet.

## Перенос знаний

Перенос знаний — это метод, который позволяет улучшить сходимость модели на новых данных за счет лучшей начальной инициализации модели. В качестве начальной инициализации в таком случае выступают веса  полученной на исходном наборе данных. Этот подход часто применяется в задачах, где имеется мало данных, но есть смежный набор данных с обученной моделью.

Данный подход предполагает использование весов нейронной сети, обученной на одних данных, для начальной инициализации весов в другой, смежной задаче. В задачах классификации этот подход обычно предполагает изменение последнего слоя, поскольку количество нейронов в последнем слое определяется количеством классов в исходном наборе данных. Например, модель, обученная на ImageNet, будет иметь 1000 нейронов на последнем слое, а модель, обученная на MNIST, будет иметь 10 нейронов. Существуют различные подходы к переносу знаний:

- Обучение всех весов нейронной сети
- Обучение весов слоев, которые были добавлены или изменены
- Обучение нескольких последних слоев
- Обучение части слоев нейронной сети

Любая подобная конфигурация является допустимой и может помочь в решении задачи. Для определения наилучшей конфигурации необходимо провести эксперименты.

В задачах классификации последний слой обычно заменяют на один или несколько слоев. Количество нейроннов в последнем слое при это должно быть равно количеству классов в новом наборе данных. Вместо последнего слоя также можно использовать классические модели машинного обучения, данный подход **нельзя** использовать в этой лабораторной работе!

##  Требования
1. Необходимо выполнить и отобразить в Jupyter следующие задачи:

    - Загрузить и проверить данные, включая демонстрацию избранных изображений и меток классов для подтверждения корректности загрузки и совпадения размерностей.
    - Загрузить 4 нейронные сети (можно использовать torchvision), обученные на наборе данных ImageNet. Требуется для каждой модели провести 2 эксперимента, используя разные конфигурация переноса знаний. Модифицировать последний слой и реализовать обучение на наборе данных Garbage Classification. Настроить гиперпараметры обучения.
    - Построить F1-score от количества эпох для всех моделей на валидационных данных. Построить сравнительную столбчатую диаграмму точностей: модель и тип эксперимента (с кратким указанием параметров) по горизонтали, F1 score на тестовых данных по вертикали.

2. Проверка корректности:

    - Разделите датасет на тренировочную, валидационную и тестовую выборки самостоятельно в соотношении 70/15/15.
    - Для оценки качества следует использовать Macro [F1-score](https://en.wikipedia.org/wiki/F-score), поскольку датасет не сбалансирован.

3. Архитектуры:

    - Можно использовать любые сверточные архитектуры или архитектуры на базе механизма внимания (transformer, ViT).
    - Хорошее понимание работы выбранных архитектур напрямую влияет на количество баллов за "знание". Будьте готовы кратко рассказать о примечательных особенностях выбранных или одной из выбранных архитектур при очной сдаче лабораторной работы. Не бойтесь выбирать сложные архитектуры - чем сложнее архитектура, тем больше шансов рассказать про нее что-то интересное и примечательное.
    
## Оценивание

Максимальное количество баллов - 30 баллов:
1. По 2 балла за каждую реализацию transfer learning (максимальное количество моделей - 4, по каждой модели 2 типа экспериментов, 4 * 2 * 0.625 = 5 баллов).
2. 0.1*<F1 score> за достигнутые результаты качества классификации
3. 15 баллов за обсуждение и демонстрацию понимания основных концепций работы.
